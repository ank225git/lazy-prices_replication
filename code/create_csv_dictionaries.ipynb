{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcef441",
   "metadata": {},
   "source": [
    "This file is for parsing the txt file into a csv file for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f40bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil\n",
    "\n",
    "# File paths\n",
    "input_path = \"../data/raw/lm_dictionaries/Loughran-McDonald_10X_DocumentDictionaries_1993-2024.txt\"\n",
    "csv_output_path = \"../data/processed/full_docdict.csv\"\n",
    "zip_output_path = \"../data/processed/full_docdict\"  # no extension here for make_archive\n",
    "\n",
    "# Make sure output folder exists\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c7cd0",
   "metadata": {},
   "source": [
    "This function is to decode the txt file structure for the parsing loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docdict_line(line):\n",
    "    header_str, wordcount_str = line.strip().split('|', maxsplit=1)\n",
    "    header_parts = header_str.split(',')\n",
    "    word_counts = wordcount_str.split(',')\n",
    "\n",
    "    header = {\n",
    "        \"cik\": header_parts[0],\n",
    "        \"filing_date\": header_parts[1],\n",
    "        \"accession_number\": header_parts[2],\n",
    "        \"report_date\": header_parts[3],\n",
    "        \"form_type\": header_parts[4],\n",
    "        \"company_name\": header_parts[5]\n",
    "    }\n",
    "\n",
    "    word_dict = {}\n",
    "    for pair in word_counts:\n",
    "        if ':' in pair:\n",
    "            idx, count = pair.split(':')\n",
    "            word_dict[f'word_{int(idx)}'] = int(count)\n",
    "\n",
    "    return header, word_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b24eb6",
   "metadata": {},
   "source": [
    "This is the loop that processes the full dictionary into a csv file. It writes processed data in chinks to not overload the memory and crash the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c6c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3b3d69c1384b2da2860b407d3168ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing and writing full filings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote batch: 10000 rows, 33960 columns\n",
      "Total rows written so far: 10000\n",
      "Wrote batch: 10000 rows, 35354 columns\n",
      "Total rows written so far: 20000\n",
      "Wrote batch: 10000 rows, 30662 columns\n",
      "Total rows written so far: 30000\n",
      "Wrote batch: 10000 rows, 38845 columns\n",
      "Total rows written so far: 40000\n",
      "Wrote batch: 10000 rows, 32015 columns\n",
      "Total rows written so far: 50000\n",
      "Wrote batch: 10000 rows, 31070 columns\n",
      "Total rows written so far: 60000\n",
      "Wrote batch: 10000 rows, 34647 columns\n",
      "Total rows written so far: 70000\n",
      "Wrote batch: 10000 rows, 34580 columns\n",
      "Total rows written so far: 80000\n",
      "Wrote batch: 10000 rows, 42536 columns\n",
      "Total rows written so far: 90000\n",
      "Wrote batch: 10000 rows, 33583 columns\n",
      "Total rows written so far: 100000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "records = []\n",
    "header_written = False\n",
    "total_rows = 0\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f_in:\n",
    "    for line in tqdm(f_in, desc=\"Parsing and writing full filings\"):\n",
    "        header, word_data = parse_docdict_line(line)\n",
    "        row = {**header, **word_data}\n",
    "        records.append(row)\n",
    "\n",
    "        if len(records) >= batch_size:\n",
    "            df_batch = pd.DataFrame(records)\n",
    "\n",
    "            if not header_written:\n",
    "                df_batch.to_csv(csv_output_path, index=False, mode='w')\n",
    "                header_written = True\n",
    "            else:\n",
    "                df_batch.to_csv(csv_output_path, index=False, mode='a', header=False)\n",
    "\n",
    "            total_rows += df_batch.shape[0]\n",
    "            print(f\"Wrote batch: {df_batch.shape[0]} rows, {df_batch.shape[1]} columns\")\n",
    "            print(f\"Total rows written so far: {total_rows}\")\n",
    "\n",
    "            records = []  # clear memory\n",
    "\n",
    "            \n",
    "# Write any remaining rows\n",
    "if records:\n",
    "    df_batch = pd.DataFrame(records)\n",
    "    if not header_written:\n",
    "        df_batch.to_csv(csv_output_path, index=False, mode='w')\n",
    "    else:\n",
    "        df_batch.to_csv(csv_output_path, index=False, mode='a', header=False)\n",
    "\n",
    "    total_rows += df_batch.shape[0]\n",
    "    print(f\"Wrote final batch: {df_batch.shape[0]} rows, {df_batch.shape[1]} columns\")\n",
    "    print(f\"Total rows written after final batch: {total_rows}\")\n",
    "\n",
    "print(\"Parsing and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be2afb",
   "metadata": {},
   "source": [
    "Zip the final .csv for faster processing in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aaa22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the final CSV\n",
    "if os.path.exists(csv_output_path) and not os.path.exists(zip_output_path + \".zip\"):\n",
    "    shutil.make_archive(zip_output_path, 'zip', root_dir=\"../data/processed\", base_dir=\"full_docdict.csv\")\n",
    "    print(\"CSV zipped successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
